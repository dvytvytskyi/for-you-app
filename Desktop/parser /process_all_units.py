#!/usr/bin/env python3
"""
–§—ñ–Ω–∞–ª—å–Ω–∞ –æ–±—Ä–æ–±–∫–∞ –≤—Å—ñ—Ö —é–Ω—ñ—Ç—ñ–≤ –∑ –ø—Ä–∞–≤–∏–ª—å–Ω–æ—é —ñ–¥–µ–Ω—Ç–∏—Ñ—ñ–∫–∞—Ü—ñ—î—é Bloque
"""

import json
import os
import requests
from ai_processor_download import AIProcessor
from datetime import datetime

def analyze_unit_identification(text_labels):
    """
    –ê–Ω–∞–ª—ñ–∑—É—î —Ç–µ–∫—Å—Ç –¥–ª—è —ñ–¥–µ–Ω—Ç–∏—Ñ—ñ–∫–∞—Ü—ñ—ó —é–Ω—ñ—Ç—É –∑ Bloque
    """
    unit_id = "UNKNOWN"
    unit_title = ""
    room_areas = {}
    total_area = ""
    
    # –®—É–∫–∞—î–º–æ –∑–∞–≥–æ–ª–æ–≤–æ–∫ —é–Ω—ñ—Ç—É –∑ Bloque
    for text in text_labels:
        text_lower = text.lower()
        
        # –®—É–∫–∞—î–º–æ —ñ–¥–µ–Ω—Ç–∏—Ñ—ñ–∫–∞—Ü—ñ—é —Ç–∏–ø—É "Bloque X Portal Y Letra Z"
        if "bloque" in text_lower and "portal" in text_lower and "letra" in text_lower:
            unit_id = text.strip()
            unit_title = text.strip()
            break
        elif "bloque" in text_lower and "portal" in text_lower:
            unit_id = text.strip()
            unit_title = text.strip()
            break
        elif "portal" in text_lower and "letra" in text_lower:
            unit_id = text.strip()
            unit_title = text.strip()
            break
    
    # –Ø–∫—â–æ –Ω–µ –∑–Ω–∞–π—à–ª–∏ –∑–∞–≥–æ–ª–æ–≤–æ–∫, —Å—Ç–≤–æ—Ä—é—î–º–æ –Ω–∞ –æ—Å–Ω–æ–≤—ñ –∫—ñ–º–Ω–∞—Ç
    if unit_id == "UNKNOWN":
        # –®—É–∫–∞—î–º–æ –∫—ñ–ª—å–∫—ñ—Å—Ç—å —Å–ø–∞–ª–µ–Ω—å
        dormitorios = [text for text in text_labels if "dormitorio" in text.lower()]
        if dormitorios:
            num_dormitorios = len(dormitorios)
            unit_id = f"2 Dormitorios" if num_dormitorios == 2 else f"{num_dormitorios} Dormitorios"
            unit_title = unit_id
    
    # –®—É–∫–∞—î–º–æ —Ä–æ–∑–º—ñ—Ä–∏ –∫—ñ–º–Ω–∞—Ç
    room_names = []
    room_sizes = []
    
    # –ó–±–∏—Ä–∞—î–º–æ –Ω–∞–∑–≤–∏ –∫—ñ–º–Ω–∞—Ç
    for text in text_labels:
        text_lower = text.lower()
        if any(room in text_lower for room in ["recibidor", "cocina", "lavadero", "ba√±o", "dormitorio", "sal√≥n", "terraza", "distribuidor"]):
            room_names.append(text.strip())
    
    # –ó–±–∏—Ä–∞—î–º–æ —Ä–æ–∑–º—ñ—Ä–∏
    for text in text_labels:
        if "m¬≤" in text:
            room_sizes.append(text.strip())
    
    # –ó'—î–¥–Ω—É—î–º–æ –Ω–∞–∑–≤–∏ –∫—ñ–º–Ω–∞—Ç –∑ —Ä–æ–∑–º—ñ—Ä–∞–º–∏
    for i, room_name in enumerate(room_names):
        if i < len(room_sizes):
            room_areas[room_name] = room_sizes[i]
    
    # –®—É–∫–∞—î–º–æ –∑–∞–≥–∞–ª—å–Ω—É –ø–ª–æ—â—É (–Ω–∞–π–±—ñ–ª—å—à–µ —á–∏—Å–ª–æ –∑ m¬≤)
    max_area = 0
    for text in text_labels:
        if "m¬≤" in text:
            try:
                import re
                area_match = re.search(r'(\d+[.,]?\d*)\s*m¬≤', text, re.IGNORECASE)
                if area_match:
                    area_value = float(area_match.group(1).replace(',', '.'))
                    if area_value > max_area and area_value > 50:  # –ó–∞–≥–∞–ª—å–Ω–∞ –ø–ª–æ—â–∞ –∑–∞–∑–≤–∏—á–∞–π >50m¬≤
                        max_area = area_value
                        total_area = text.strip()
            except:
                pass
    
    # –Ø–∫—â–æ –Ω–µ –∑–Ω–∞–π—à–ª–∏ –∑–∞–≥–∞–ª—å–Ω—É –ø–ª–æ—â—É, —Å—É–º—É—î–º–æ –≤—Å—ñ —Ä–æ–∑–º—ñ—Ä–∏
    if not total_area and room_sizes:
        try:
            total_sum = 0
            for size_text in room_sizes:
                area_match = re.search(r'(\d+[.,]?\d*)', size_text)
                if area_match:
                    total_sum += float(area_match.group(1).replace(',', '.'))
            total_area = f"{total_sum:.1f} m¬≤"
        except:
            pass
    
    return {
        "unit_id": unit_id,
        "unit_title": unit_title,
        "room_areas": room_areas,
        "total_area": total_area
    }

def process_all_units():
    """–û–±—Ä–æ–±–∫–∞ –≤—Å—ñ—Ö —é–Ω—ñ—Ç—ñ–≤"""
    
    # API –∫–ª—é—á Google AI Studio
    API_KEY = "AIzaSyC0oK7s9qOjZW-Jv9YGCmQlwBkr8K-xMzY"
    
    # –°—Ç–≤–æ—Ä—é—î–º–æ AI –ø—Ä–æ—Ü–µ—Å–æ—Ä
    ai_processor = AIProcessor(API_KEY)
    
    # –®–ª—è—Ö –¥–æ initial.json
    initial_json_path = "projects/MEDBLUE_MARBELLA/initial.json"
    
    # –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ –¥–∞–Ω—ñ –∑ initial.json
    try:
        with open(initial_json_path, 'r', encoding='utf-8') as f:
            initial_data = json.load(f)
    except Exception as e:
        print(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è initial.json: {str(e)}")
        return
    
    # –û—Ç—Ä–∏–º—É—î–º–æ –ø–ª–∞–Ω–∏
    plans_data = initial_data.get("plans", {})
    plans_images = plans_data.get("plans_images", [])
    
    # –§—ñ–ª—å—Ç—Ä—É—î–º–æ —Ç—ñ–ª—å–∫–∏ –ø–ª–∞–Ω–∏ –∑ planos_div
    unit_plans = []
    for plan in plans_images:
        if plan.get("location") == "planos_div":
            unit_plans.append(plan)
    
    print(f"üìê –ó–Ω–∞–π–¥–µ–Ω–æ {len(unit_plans)} –ø–ª–∞–Ω—ñ–≤ —é–Ω—ñ—Ç—ñ–≤")
    
    # –°—Ç–≤–æ—Ä—é—î–º–æ –ø–∞–ø–∫—É plans —è–∫—â–æ –Ω–µ —ñ—Å–Ω—É—î
    plans_dir = "projects/MEDBLUE_MARBELLA/plans"
    os.makedirs(plans_dir, exist_ok=True)
    
    # –û–±—Ä–æ–±–ª—è—î–º–æ –≤—Å—ñ —é–Ω—ñ—Ç–∏
    units_analysis = []
    
    for i, plan in enumerate(unit_plans):
        try:
            image_url = plan.get("src", "")
            plan_index = plan.get("index", i)
            
            if not image_url:
                print(f"‚ùå –ü–ª–∞–Ω {i+1}: –≤—ñ–¥—Å—É—Ç–Ω—ñ–π URL")
                continue
            
            print(f"üîç –û–±—Ä–æ–±–∫–∞ —é–Ω—ñ—Ç—É {i+1}/{len(unit_plans)} (—ñ–Ω–¥–µ–∫—Å: {plan_index})")
            
            # –ê–Ω–∞–ª—ñ–∑—É—î–º–æ –ø–ª–∞–Ω —á–µ—Ä–µ–∑ AI –¥–ª—è –æ—Ç—Ä–∏–º–∞–Ω–Ω—è —Ç–µ–∫—Å—Ç—É
            structured_data = ai_processor.analyze_plans(image_url, plan_index)
            
            if structured_data:
                # –û—Ç—Ä–∏–º—É—î–º–æ —Ç–µ–∫—Å—Ç –∑ –∞–Ω–æ—Ç–∞—Ü—ñ–π
                text_labels = structured_data.get("plan_annotations", {}).get("text_labels", [])
                dimensions = structured_data.get("plan_annotations", {}).get("dimensions", [])
                
                # –ê–Ω–∞–ª—ñ–∑—É—î–º–æ —Ç–µ–∫—Å—Ç –¥–ª—è —ñ–¥–µ–Ω—Ç–∏—Ñ—ñ–∫–∞—Ü—ñ—ó —é–Ω—ñ—Ç—É
                unit_identification = analyze_unit_identification(text_labels)
                
                # –°—Ç–≤–æ—Ä—é—î–º–æ —Å—Ç—Ä—É–∫—Ç—É—Ä—É –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ —é–Ω—ñ—Ç—É
                unit_data = {
                    "unit_id": unit_identification.get("unit_id", f"UNIT_{plan_index:03d}"),
                    "unit_identification": unit_identification,
                    "plan_index": plan_index,
                    "image_url": image_url,
                    "analysis_timestamp": datetime.now().isoformat(),
                    "unit_type": structured_data.get("plan_type", "unknown"),
                    "text_analysis": {
                        "all_text_labels": text_labels,
                        "dimensions_text": dimensions,
                        "unit_title": unit_identification.get("unit_title", ""),
                        "room_areas": unit_identification.get("room_areas", {}),
                        "total_area": unit_identification.get("total_area", "")
                    }
                }
                
                units_analysis.append(unit_data)
                print(f"‚úÖ –Æ–Ω—ñ—Ç {i+1} —É—Å–ø—ñ—à–Ω–æ –æ–±—Ä–æ–±–ª–µ–Ω–æ")
                print(f"   ID: {unit_data['unit_id']}")
                print(f"   –¢–∏–ø: {unit_data['unit_type']}")
                print(f"   –ü–ª–æ—â–∞: {unit_data['text_analysis']['total_area']}")
            else:
                print(f"‚ùå –Æ–Ω—ñ—Ç {i+1} –Ω–µ –≤–¥–∞–ª–æ—Å—è –æ–±—Ä–æ–±–∏—Ç–∏")
                
        except Exception as e:
            print(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –æ–±—Ä–æ–±–∫–∏ —é–Ω—ñ—Ç—É {i+1}: {str(e)}")
    
    # –°—Ç–≤–æ—Ä—é—î–º–æ –∑–∞–≥–∞–ª—å–Ω—É —Å—Ç—Ä—É–∫—Ç—É—Ä—É
    analysis_result = {
        "project_name": "MEDBLUE MARBELLA",
        "analysis_date": datetime.now().isoformat(),
        "total_units_available": len(unit_plans),
        "units_analyzed": len(units_analysis),
        "units_data": units_analysis,
        "analysis_summary": {
            "unit_types_found": list(set([unit["unit_type"] for unit in units_analysis])),
            "unit_identifications": [unit["unit_id"] for unit in units_analysis],
            "total_areas_identified": len([unit for unit in units_analysis if unit["text_analysis"]["total_area"]])
        }
    }
    
    # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç
    output_path = os.path.join(plans_dir, "all_units_analysis.json")
    
    try:
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(analysis_result, f, ensure_ascii=False, indent=2)
        
        print(f"üíæ –†–µ–∑—É–ª—å—Ç–∞—Ç –∑–±–µ—Ä–µ–∂–µ–Ω–æ: {output_path}")
        print(f"üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
        print(f"   - –û–±—Ä–æ–±–ª–µ–Ω–æ —é–Ω—ñ—Ç—ñ–≤: {len(units_analysis)}")
        print(f"   - –¢–∏–ø–∏ —é–Ω—ñ—Ç—ñ–≤: {analysis_result['analysis_summary']['unit_types_found']}")
        print(f"   - –ü–ª–æ—â—ñ –∑–Ω–∞–π–¥–µ–Ω–æ: {analysis_result['analysis_summary']['total_areas_identified']}")
        
    except Exception as e:
        print(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è: {str(e)}")

if __name__ == "__main__":
    process_all_units()
